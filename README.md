# etl-project


The project task was to build a batch ETL pipeline -  

  to ingest transactional data from RDS into HDFS (using AWS EMR) via Sqoop
  
  to transform the data using PySpark (using AWS EMR) to create relevant dimension and fact tables (Data Mart) 
  
  to upload these tables into AWS S3 buckets
  
  load them from S3 into AWS Redshift tables
  
  to perform various KPI on the data


